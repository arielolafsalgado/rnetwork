<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>CRAN - Package shattering</title>
<link rel="stylesheet" type="text/css" href="../../CRAN_web.css" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="citation_title" content="Estimate the Shattering Coefficient for a Particular Dataset [R package shattering version 1.0.3]" />
<meta name="citation_author" content="Rodrigo F. de Mello" />
<meta name="citation_publication_date" content="2020-10-17" />
<meta name="citation_public_url" content="https://CRAN.R-project.org/package=shattering" />
<meta name="DC.identifier" content="https://CRAN.R-project.org/package=shattering" />
<meta name="DC.publisher" content="Comprehensive R Archive Network (CRAN)" />
<meta name="og:title" content="shattering: Estimate the Shattering Coefficient for a Particular Dataset" />
<meta name="og:description" content="The Statistical Learning Theory (SLT) provides the theoretical background to ensure that a supervised algorithm generalizes the mapping f:X -&amp;gt; Y given f is selected from its search space bias F. This formal result depends on the Shattering coefficient function N(F,2n) to upper bound the empirical risk minimization principle, from which one can estimate the necessary training sample size to ensure the probabilistic learning convergence and, most importantly, the characterization of the capacity of F, including its under and overfitting abilities while addressing specific target problems. In this context, we propose a new approach to estimate the maximal number of hyperplanes required to shatter a given sample, i.e., to separate every pair of points from one another, based on the recent contributions by Har-Peled and Jones in the dataset partitioning scenario, and use such foundation to analytically compute the Shattering coefficient function for both binary and multi-class problems. As main contributions, one can use our approach to study the complexity of the search space bias F, estimate training sample sizes, and parametrize the number of hyperplanes a learning algorithm needs to address some supervised task, what is specially appealing to deep neural networks. Reference: de Mello, R.F. (2019) &quot;On the Shattering Coefficient of Supervised Learning Algorithms&quot; &amp;lt;&lt;a href=&quot;https://arxiv.org/abs/1911.05461&quot;&gt;arXiv:1911.05461&lt;/a&gt;&amp;gt;; de Mello, R.F., Ponti, M.A. (2018, ISBN: 978-3319949888) &quot;Machine Learning: A Practical Approach on the Statistical Learning Theory&quot;." />
<meta name="og:image" content="https://CRAN.R-project.org/CRANlogo.png" />
<meta name="og:type" content="website" />
<meta name="og:url" content="https://CRAN.R-project.org/package=shattering" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@_R_Foundation" />
<style type="text/css">
  table td { vertical-align: top; }
</style>
</head>
<body>
<h2>shattering: Estimate the Shattering Coefficient for a Particular Dataset</h2>
<p>The Statistical Learning Theory (SLT) provides the theoretical background to ensure that a supervised algorithm generalizes the mapping f:X -&gt; Y given f is selected from its search space bias F. This formal result depends on the Shattering coefficient function N(F,2n) to upper bound the empirical risk minimization principle, from which one can estimate the necessary training sample size to ensure the probabilistic learning convergence and, most importantly, the characterization of the capacity of F, including its under and overfitting abilities while addressing specific target problems. In this context, we propose a new approach to estimate the maximal number of hyperplanes required to shatter a given sample, i.e., to separate every pair of points from one another, based on the recent contributions by Har-Peled and Jones in the dataset partitioning scenario, and use such foundation to analytically compute the Shattering coefficient function for both binary and multi-class problems. As main contributions, one can use our approach to study the complexity of the search space bias F, estimate training sample sizes, and parametrize the number of hyperplanes a learning algorithm needs to address some supervised task, what is specially appealing to deep neural networks. Reference: de Mello, R.F. (2019) "On the Shattering Coefficient of Supervised Learning Algorithms" &lt;<a href="https://arxiv.org/abs/1911.05461">arXiv:1911.05461</a>&gt;; de Mello, R.F., Ponti, M.A. (2018, ISBN: 978-3319949888) "Machine Learning: A Practical Approach on the Statistical Learning Theory".</p>
<table summary="Package shattering summary">
<tr>
<td>Version:</td>
<td>1.0.3</td>
</tr>
<tr>
<td>Imports:</td>
<td><a href="../FNN/index.html">FNN</a>, <a href="../pdist/index.html">pdist</a>, <a href="../slam/index.html">slam</a>, grDevices, <a href="../Ryacas/index.html">Ryacas</a>, <a href="../rmarkdown/index.html">rmarkdown</a>, <a href="../pracma/index.html">pracma</a>, graphics</td>
</tr>
<tr>
<td>Suggests:</td>
<td><a href="../testthat/index.html">testthat</a></td>
</tr>
<tr>
<td>Published:</td>
<td>2020-10-17</td>
</tr>
<tr>
<td>Author:</td>
<td>Rodrigo F. de Mello
    <a href="https://orcid.org/0000-0002-0435-3992"><img alt="ORCID iD" src="/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Rodrigo F. de Mello  &#x3c;&#x6d;&#x65;&#x6c;&#x6c;&#x6f;&#x20;&#x61;&#x74;&#x20;&#x69;&#x63;&#x6d;&#x63;&#x2e;&#x75;&#x73;&#x70;&#x2e;&#x62;&#x72;&#x3e;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="../../licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>CRAN&nbsp;checks:</td>
<td><a href="../../checks/check_results_shattering.html">shattering results</a></td>
</tr>
</table>
<h4>Downloads:</h4>
<table summary="Package shattering downloads">
<tr>
<td> Reference&nbsp;manual: </td>
<td> <a href="shattering.pdf"> shattering.pdf </a> </td>
</tr>
<tr>
<td> Package&nbsp;source: </td>
<td> <a href="../../../src/contrib/shattering_1.0.3.tar.gz"> shattering_1.0.3.tar.gz </a> </td>
</tr>
<tr>
<td> Windows&nbsp;binaries: </td>
<td> r-devel: <a href="../../../bin/windows/contrib/4.1/shattering_1.0.3.zip">shattering_1.0.3.zip</a>, r-release: <a href="../../../bin/windows/contrib/4.0/shattering_1.0.3.zip">shattering_1.0.3.zip</a>, r-oldrel: <a href="../../../bin/windows/contrib/3.6/shattering_1.0.3.zip">shattering_1.0.3.zip</a> </td>
</tr>
<tr>
<td> macOS&nbsp;binaries: </td>
<td> r-release: <a href="../../../bin/macosx/contrib/4.0/shattering_1.0.3.tgz">shattering_1.0.3.tgz</a>, r-oldrel: <a href="../../../bin/macosx/el-capitan/contrib/3.6/shattering_1.0.3.tgz">shattering_1.0.3.tgz</a> </td>
</tr>
<tr>
<td> Old&nbsp;sources: </td>
<td> <a href="https://CRAN.R-project.org/src/contrib/Archive/shattering"> shattering archive </a> </td>
</tr>
</table>
<h4>Linking:</h4>
<p>Please use the canonical form
<a href="https://CRAN.R-project.org/package=shattering"><samp>https://CRAN.R-project.org/package=shattering</samp></a>
to link to this page.</p>
</body>
</html>
