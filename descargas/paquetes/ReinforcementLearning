<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>CRAN - Package ReinforcementLearning</title>
<link rel="stylesheet" type="text/css" href="../../CRAN_web.css" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="citation_title" content="Model-Free Reinforcement Learning [R package ReinforcementLearning version 1.0.5]" />
<meta name="citation_author1" content="Nicolas Proellochs" />
<meta name="citation_author2" content="Stefan Feuerriegel" />
<meta name="citation_publication_date" content="2020-03-02" />
<meta name="citation_public_url" content="https://CRAN.R-project.org/package=ReinforcementLearning" />
<meta name="DC.identifier" content="https://CRAN.R-project.org/package=ReinforcementLearning" />
<meta name="DC.publisher" content="Comprehensive R Archive Network (CRAN)" />
<meta name="og:title" content="ReinforcementLearning: Model-Free Reinforcement Learning" />
<meta name="og:description" content="Performs model-free reinforcement learning in R. This implementation enables the learning of an optimal policy based on sample sequences consisting of states, actions and rewards. In addition, it supplies multiple predefined reinforcement learning algorithms, such as experience replay. Methodological details can be found in Sutton and Barto (1998) &amp;lt;ISBN:0262039249&amp;gt;." />
<meta name="og:image" content="https://CRAN.R-project.org/CRANlogo.png" />
<meta name="og:type" content="website" />
<meta name="og:url" content="https://CRAN.R-project.org/package=ReinforcementLearning" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@_R_Foundation" />
<style type="text/css">
  table td { vertical-align: top; }
</style>
</head>
<body>
<h2>ReinforcementLearning: Model-Free Reinforcement Learning</h2>
<p>Performs model-free reinforcement learning in R. This implementation enables the learning
    of an optimal policy based on sample sequences consisting of states, actions and rewards. In 
    addition, it supplies multiple predefined reinforcement learning algorithms, such as experience 
    replay. Methodological details can be found in Sutton and Barto (1998) &lt;ISBN:0262039249&gt;.</p>
<table summary="Package ReinforcementLearning summary">
<tr>
<td>Version:</td>
<td>1.0.5</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td><a href="../ggplot2/index.html">ggplot2</a>, <a href="../hash/index.html">hash</a> (&ge; 2.0), <a href="../data.table/index.html">data.table</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td><a href="../testthat/index.html">testthat</a>, <a href="../knitr/index.html">knitr</a>, <a href="../rmarkdown/index.html">rmarkdown</a></td>
</tr>
<tr>
<td>Published:</td>
<td>2020-03-02</td>
</tr>
<tr>
<td>Author:</td>
<td>Nicolas Proellochs [aut, cre],
  Stefan Feuerriegel [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nicolas Proellochs  &#x3c;&#x6e;&#x69;&#x63;&#x6f;&#x6c;&#x61;&#x73;&#x2e;&#x70;&#x72;&#x6f;&#x65;&#x6c;&#x6c;&#x6f;&#x63;&#x68;&#x73;&#x20;&#x61;&#x74;&#x20;&#x77;&#x69;&#x2e;&#x6a;&#x6c;&#x75;&#x67;&#x2e;&#x64;&#x65;&#x3e;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="../../licenses/MIT">MIT</a> + file <a href="LICENSE">LICENSE</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Materials:</td>
<td><a href="readme/README.html">README</a> <a href="news/news.html">NEWS</a> </td>
</tr>
<tr>
<td>CRAN&nbsp;checks:</td>
<td><a href="../../checks/check_results_ReinforcementLearning.html">ReinforcementLearning results</a></td>
</tr>
</table>
<h4>Downloads:</h4>
<table summary="Package ReinforcementLearning downloads">
<tr>
<td> Reference&nbsp;manual: </td>
<td> <a href="ReinforcementLearning.pdf"> ReinforcementLearning.pdf </a> </td>
</tr>
<tr>
<td>Vignettes:</td>
<td>
<a href="vignettes/ReinforcementLearning.html">Reinforcement Learning in R</a><br/>
</td>
</tr>
<tr>
<td> Package&nbsp;source: </td>
<td> <a href="../../../src/contrib/ReinforcementLearning_1.0.5.tar.gz"> ReinforcementLearning_1.0.5.tar.gz </a> </td>
</tr>
<tr>
<td> Windows&nbsp;binaries: </td>
<td> r-devel: <a href="../../../bin/windows/contrib/4.1/ReinforcementLearning_1.0.5.zip">ReinforcementLearning_1.0.5.zip</a>, r-release: <a href="../../../bin/windows/contrib/4.0/ReinforcementLearning_1.0.5.zip">ReinforcementLearning_1.0.5.zip</a>, r-oldrel: <a href="../../../bin/windows/contrib/3.6/ReinforcementLearning_1.0.5.zip">ReinforcementLearning_1.0.5.zip</a> </td>
</tr>
<tr>
<td> macOS&nbsp;binaries: </td>
<td> r-release: <a href="../../../bin/macosx/contrib/4.0/ReinforcementLearning_1.0.5.tgz">ReinforcementLearning_1.0.5.tgz</a>, r-oldrel: <a href="../../../bin/macosx/el-capitan/contrib/3.6/ReinforcementLearning_1.0.5.tgz">ReinforcementLearning_1.0.5.tgz</a> </td>
</tr>
<tr>
<td> Old&nbsp;sources: </td>
<td> <a href="https://CRAN.R-project.org/src/contrib/Archive/ReinforcementLearning"> ReinforcementLearning archive </a> </td>
</tr>
</table>
<h4>Reverse dependencies:</h4>
<table summary="Package ReinforcementLearning reverse dependencies">
<tr>
<td>Reverse&nbsp;imports:</td>
<td><a href="../lazytrade/index.html">lazytrade</a></td>
</tr>
</table>
<h4>Linking:</h4>
<p>Please use the canonical form
<a href="https://CRAN.R-project.org/package=ReinforcementLearning"><samp>https://CRAN.R-project.org/package=ReinforcementLearning</samp></a>
to link to this page.</p>
</body>
</html>
