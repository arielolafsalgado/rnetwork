<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>CRAN - Package robotstxt</title>
<link rel="stylesheet" type="text/css" href="../../CRAN_web.css" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="citation_title" content="A 'robots.txt' Parser and 'Webbot'/'Spider'/'Crawler' Permissions Checker [R package robotstxt version 0.7.13]" />
<meta name="citation_author1" content="Peter Meissner" />
<meta name="citation_author2" content="Kun Ren" />
<meta name="citation_publication_date" content="2020-09-03" />
<meta name="citation_public_url" content="https://CRAN.R-project.org/package=robotstxt" />
<meta name="DC.identifier" content="https://CRAN.R-project.org/package=robotstxt" />
<meta name="DC.publisher" content="Comprehensive R Archive Network (CRAN)" />
<meta name="og:title" content="robotstxt: A 'robots.txt' Parser and 'Webbot'/'Spider'/'Crawler' Permissions Checker" />
<meta name="og:description" content="Provides functions to download and parse 'robots.txt' files. Ultimately the package makes it easy to check if bots (spiders, crawler, scrapers, ...) are allowed to access specific resources on a domain." />
<meta name="og:image" content="https://CRAN.R-project.org/CRANlogo.png" />
<meta name="og:type" content="website" />
<meta name="og:url" content="https://CRAN.R-project.org/package=robotstxt" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@_R_Foundation" />
<style type="text/css">
  table td { vertical-align: top; }
</style>
</head>
<body>
<h2>robotstxt: A 'robots.txt' Parser and 'Webbot'/'Spider'/'Crawler'
Permissions Checker</h2>
<p>Provides functions to download and parse 'robots.txt' files.
        Ultimately the package makes it easy to check if bots
        (spiders, crawler, scrapers, ...) are allowed to access specific
        resources on a domain.</p>
<table summary="Package robotstxt summary">
<tr>
<td>Version:</td>
<td>0.7.13</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td><a href="../stringr/index.html">stringr</a> (&ge; 1.0.0), <a href="../httr/index.html">httr</a> (&ge; 1.0.0), <a href="../spiderbar/index.html">spiderbar</a> (&ge; 0.2.0), <a href="../future/index.html">future</a> (&ge; 1.6.2), <a href="../future.apply/index.html">future.apply</a> (&ge; 1.0.0), <a href="../magrittr/index.html">magrittr</a>, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td><a href="../knitr/index.html">knitr</a>, <a href="../rmarkdown/index.html">rmarkdown</a>, <a href="../dplyr/index.html">dplyr</a>, <a href="../testthat/index.html">testthat</a>, <a href="../covr/index.html">covr</a></td>
</tr>
<tr>
<td>Published:</td>
<td>2020-09-03</td>
</tr>
<tr>
<td>Author:</td>
<td>Peter Meissner [aut, cre],
  Kun Ren [aut, cph] (Author and copyright holder of list_merge.R.),
  Oliver Keys [ctb] (original release code review),
  Rich Fitz John [ctb] (original release code review)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Peter Meissner  &#x3c;&#x72;&#x65;&#x74;&#x65;&#x70;&#x2e;&#x6d;&#x65;&#x69;&#x73;&#x73;&#x6e;&#x65;&#x72;&#x20;&#x61;&#x74;&#x20;&#x67;&#x6d;&#x61;&#x69;&#x6c;&#x2e;&#x63;&#x6f;&#x6d;&#x3e;</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ropensci/robotstxt/issues">https://github.com/ropensci/robotstxt/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="../../licenses/MIT">MIT</a> + file <a href="LICENSE">LICENSE</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://docs.ropensci.org/robotstxt/">https://docs.ropensci.org/robotstxt/</a>,
<a href="https://github.com/ropensci/robotstxt">https://github.com/ropensci/robotstxt</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Materials:</td>
<td><a href="readme/README.html">README</a> <a href="news/news.html">NEWS</a> </td>
</tr>
<tr>
<td>In&nbsp;views:</td>
<td><a href="../../views/WebTechnologies.html">WebTechnologies</a></td>
</tr>
<tr>
<td>CRAN&nbsp;checks:</td>
<td><a href="../../checks/check_results_robotstxt.html">robotstxt results</a></td>
</tr>
</table>
<h4>Downloads:</h4>
<table summary="Package robotstxt downloads">
<tr>
<td> Reference&nbsp;manual: </td>
<td> <a href="robotstxt.pdf"> robotstxt.pdf </a> </td>
</tr>
<tr>
<td>Vignettes:</td>
<td>
<a href="vignettes/using_robotstxt.html">using_robotstxt</a><br/>
</td>
</tr>
<tr>
<td> Package&nbsp;source: </td>
<td> <a href="../../../src/contrib/robotstxt_0.7.13.tar.gz"> robotstxt_0.7.13.tar.gz </a> </td>
</tr>
<tr>
<td> Windows&nbsp;binaries: </td>
<td> r-devel: <a href="../../../bin/windows/contrib/4.1/robotstxt_0.7.13.zip">robotstxt_0.7.13.zip</a>, r-release: <a href="../../../bin/windows/contrib/4.0/robotstxt_0.7.13.zip">robotstxt_0.7.13.zip</a>, r-oldrel: <a href="../../../bin/windows/contrib/3.6/robotstxt_0.7.13.zip">robotstxt_0.7.13.zip</a> </td>
</tr>
<tr>
<td> macOS&nbsp;binaries: </td>
<td> r-release: <a href="../../../bin/macosx/contrib/4.0/robotstxt_0.7.13.tgz">robotstxt_0.7.13.tgz</a>, r-oldrel: <a href="../../../bin/macosx/el-capitan/contrib/3.6/robotstxt_0.7.13.tgz">robotstxt_0.7.13.tgz</a> </td>
</tr>
<tr>
<td> Old&nbsp;sources: </td>
<td> <a href="https://CRAN.R-project.org/src/contrib/Archive/robotstxt"> robotstxt archive </a> </td>
</tr>
</table>
<h4>Reverse dependencies:</h4>
<table summary="Package robotstxt reverse dependencies">
<tr>
<td>Reverse&nbsp;imports:</td>
<td><a href="../polite/index.html">polite</a>, <a href="../ralger/index.html">ralger</a></td>
</tr>
<tr>
<td>Reverse&nbsp;suggests:</td>
<td><a href="../newsanchor/index.html">newsanchor</a>, <a href="../spiderbar/index.html">spiderbar</a>, <a href="../webchem/index.html">webchem</a></td>
</tr>
</table>
<h4>Linking:</h4>
<p>Please use the canonical form
<a href="https://CRAN.R-project.org/package=robotstxt"><samp>https://CRAN.R-project.org/package=robotstxt</samp></a>
to link to this page.</p>
</body>
</html>
