<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>CRAN - Package PubBias</title>
<link rel="stylesheet" type="text/css" href="../../CRAN_web.css" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="DC.identifier" content="https://CRAN.R-project.org/package=PubBias" />
<meta name="DC.publisher" content="Comprehensive R Archive Network (CRAN)" />
<meta name="og:title" content="PubBias: Performs simulation study to look for publication bias, using a technique described by Ioannidis and Trikalinos; Clin Trials. 2007;4(3):245-53" />
<meta name="og:description" content="I adapted a method designed by Ioannidis and Trikalinos, which compares the observed number of positive studies in a meta-analysis with the expected number, if the summary measure of effect, averaged over the individual studies, were assumed true. Excess in the observed number of positive studies, compared to the expected, is taken as evidence of publication bias. The observed number of positive studies, at a given level for statistical significance, is calculated by applying Fisher's exact test to the reported 2x2 table data of each constituent study, doubling the Fisher one-sided P-value to make a two-sided test. The corresponding expected number of positive studies was obtained by summing the statistical powers of each study. The statistical power depended on a given measure of effect which, here, was the pooled odds ratio of the meta-analysis was used. By simulating each constituent study, with the given odds ratio, and the same number of treated and non-treated as in the real study, the power of the study is estimated as the proportion of simulated studies that are positive, again by a Fisher's exact test. The simulated number of events in the treated and untreated groups was done with binomial sampling. In the untreated group, the binomial proportion was the percentage of actual events reported in the study and, in the treated group, the binomial sampling proportion was the untreated percentage multiplied by the risk ratio which was derived from the assumed common odds ratio. The statistical significance for judging a positive study may be varied and large differences between expected and observed number of positive studies around the level of 0.05 significance constitutes evidence of publication bias. The difference between the observed and expected is tested by chi-square. A chi-square test P-value for the difference below 0.05 is suggestive of publication bias, however, a less stringent level of 0.1 is often used in studies of publication bias as the number of published studies is usually small." />
<meta name="og:image" content="https://CRAN.R-project.org/CRANlogo.png" />
<meta name="og:type" content="website" />
<meta name="og:url" content="https://CRAN.R-project.org/package=PubBias" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@_R_Foundation" />
<style type="text/css">
  table td { vertical-align: top; }
</style>
</head>
<body>
<h2>PubBias: Performs simulation study to look for publication bias, using a
technique described by Ioannidis and Trikalinos; Clin Trials.
2007;4(3):245-53</h2>
<p>I adapted a method designed by Ioannidis and Trikalinos, which
    compares the observed number of positive studies in a meta-analysis with
    the expected number, if the summary measure of effect, averaged over the
    individual studies, were assumed true. Excess in the observed number of
    positive studies, compared to the expected, is taken as evidence of
    publication bias. The observed number of positive studies, at a given level
    for statistical significance, is calculated by applying Fisher's exact test
    to the reported 2x2 table data of each constituent study, doubling the
    Fisher one-sided P-value to make a two-sided test. The corresponding
    expected number of positive studies was obtained by summing the statistical
    powers of each study. The statistical power depended on a given measure of
    effect which, here, was the pooled odds ratio of the meta-analysis was
    used. By simulating each constituent study, with the given odds ratio, and
    the same number of treated and non-treated as in the real study, the power
    of the study is estimated as the proportion of simulated studies that are
    positive, again by a Fisher's exact test. The simulated number of events in
    the treated and untreated groups was done with binomial sampling. In the
    untreated group, the binomial proportion was the percentage of actual
    events reported in the study and, in the treated group, the binomial
    sampling proportion was the untreated percentage multiplied by the risk
    ratio which was derived from the assumed common odds ratio. The statistical
    significance for judging a positive study may be varied and large
    differences between expected and observed number of positive studies around
    the level of 0.05 significance constitutes evidence of publication bias.
    The difference between the observed and expected is tested by chi-square. A
    chi-square test P-value for the difference below 0.05 is suggestive of
    publication bias, however, a less stringent level of 0.1 is often used in
    studies of publication bias as the number of published studies is usually
    small.</p>
<table summary="Package PubBias summary">
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Depends:</td>
<td><a href="../rmeta/index.html">rmeta</a>, <a href="../R.utils/index.html">R.utils</a></td>
</tr>
<tr>
<td>Published:</td>
<td>2013-11-21</td>
</tr>
<tr>
<td>Author:</td>
<td>Simon Thornley</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Simon Thornley  &#x3c;&#x73;&#x69;&#x74;&#x68;&#x6f;&#x72;&#x20;&#x61;&#x74;&#x20;&#x67;&#x6d;&#x61;&#x69;&#x6c;&#x2e;&#x63;&#x6f;&#x6d;&#x3e;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="../../licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>In&nbsp;views:</td>
<td><a href="../../views/MetaAnalysis.html">MetaAnalysis</a></td>
</tr>
<tr>
<td>CRAN&nbsp;checks:</td>
<td><a href="../../checks/check_results_PubBias.html">PubBias results</a></td>
</tr>
</table>
<h4>Downloads:</h4>
<table summary="Package PubBias downloads">
<tr>
<td> Reference&nbsp;manual: </td>
<td> <a href="PubBias.pdf"> PubBias.pdf </a> </td>
</tr>
<tr>
<td> Package&nbsp;source: </td>
<td> <a href="../../../src/contrib/PubBias_1.0.tar.gz"> PubBias_1.0.tar.gz </a> </td>
</tr>
<tr>
<td> Windows&nbsp;binaries: </td>
<td> r-devel: <a href="../../../bin/windows/contrib/4.1/PubBias_1.0.zip">PubBias_1.0.zip</a>, r-release: <a href="../../../bin/windows/contrib/4.0/PubBias_1.0.zip">PubBias_1.0.zip</a>, r-oldrel: <a href="../../../bin/windows/contrib/3.6/PubBias_1.0.zip">PubBias_1.0.zip</a> </td>
</tr>
<tr>
<td> macOS&nbsp;binaries: </td>
<td> r-release: <a href="../../../bin/macosx/contrib/4.0/PubBias_1.0.tgz">PubBias_1.0.tgz</a>, r-oldrel: <a href="../../../bin/macosx/el-capitan/contrib/3.6/PubBias_1.0.tgz">PubBias_1.0.tgz</a> </td>
</tr>
</table>
<h4>Linking:</h4>
<p>Please use the canonical form
<a href="https://CRAN.R-project.org/package=PubBias"><samp>https://CRAN.R-project.org/package=PubBias</samp></a>
to link to this page.</p>
</body>
</html>
