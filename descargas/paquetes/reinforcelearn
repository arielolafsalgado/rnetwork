<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>CRAN - Package reinforcelearn</title>
<link rel="stylesheet" type="text/css" href="../../CRAN_web.css" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="citation_title" content="Reinforcement Learning [R package reinforcelearn version 0.2.1]" />
<meta name="citation_author" content="Markus Dumke" />
<meta name="citation_publication_date" content="2019-04-09" />
<meta name="citation_public_url" content="https://CRAN.R-project.org/package=reinforcelearn" />
<meta name="DC.identifier" content="https://CRAN.R-project.org/package=reinforcelearn" />
<meta name="DC.publisher" content="Comprehensive R Archive Network (CRAN)" />
<meta name="og:title" content="reinforcelearn: Reinforcement Learning" />
<meta name="og:description" content="Implements reinforcement learning environments and algorithms as described in Sutton &amp;amp; Barto (1998, ISBN:0262193981). The Q-Learning algorithm can be used with function approximation, eligibility traces (Singh &amp;amp; Sutton (1996) &amp;lt;&lt;a href=&quot;https://doi.org/10.1007%2FBF00114726&quot;&gt;doi:10.1007/BF00114726&lt;/a&gt;&amp;gt;) and experience replay (Mnih et al. (2013) &amp;lt;&lt;a href=&quot;https://arxiv.org/abs/1312.5602&quot;&gt;arXiv:1312.5602&lt;/a&gt;&amp;gt;)." />
<meta name="og:image" content="https://CRAN.R-project.org/CRANlogo.png" />
<meta name="og:type" content="website" />
<meta name="og:url" content="https://CRAN.R-project.org/package=reinforcelearn" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@_R_Foundation" />
<style type="text/css">
  table td { vertical-align: top; }
</style>
</head>
<body>
<h2>reinforcelearn: Reinforcement Learning</h2>
<p>Implements reinforcement learning environments and algorithms as described in Sutton &amp; Barto (1998, ISBN:0262193981).
    The Q-Learning algorithm can be used with function approximation, 
    eligibility traces (Singh &amp; Sutton (1996) &lt;<a href="https://doi.org/10.1007%2FBF00114726">doi:10.1007/BF00114726</a>&gt;) 
    and experience replay (Mnih et al. (2013) &lt;<a href="https://arxiv.org/abs/1312.5602">arXiv:1312.5602</a>&gt;).</p>
<table summary="Package reinforcelearn summary">
<tr>
<td>Version:</td>
<td>0.2.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td><a href="../checkmate/index.html">checkmate</a> (&ge; 1.8.4), <a href="../R6/index.html">R6</a> (&ge; 2.2.2), <a href="../nnet/index.html">nnet</a> (&ge; 7.3-12), <a href="../purrr/index.html">purrr</a> (&ge; 0.2.4)</td>
</tr>
<tr>
<td>Suggests:</td>
<td><a href="../reticulate/index.html">reticulate</a>, <a href="../keras/index.html">keras</a>, <a href="../knitr/index.html">knitr</a>, <a href="../rmarkdown/index.html">rmarkdown</a>, <a href="../testthat/index.html">testthat</a>, <a href="../covr/index.html">covr</a>, <a href="../lintr/index.html">lintr</a></td>
</tr>
<tr>
<td>Published:</td>
<td>2019-04-09</td>
</tr>
<tr>
<td>Author:</td>
<td>Markus Dumke [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Markus Dumke  &#x3c;&#x6d;&#x61;&#x72;&#x6b;&#x75;&#x73;&#x64;&#x75;&#x6d;&#x6b;&#x65;&#x20;&#x61;&#x74;&#x20;&#x67;&#x6d;&#x61;&#x69;&#x6c;&#x2e;&#x63;&#x6f;&#x6d;&#x3e;</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/markusdumke/reinforcelearn/issues">https://github.com/markusdumke/reinforcelearn/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="../../licenses/MIT">MIT</a> + file <a href="LICENSE">LICENSE</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://markusdumke.github.io/reinforcelearn">http://markusdumke.github.io/reinforcelearn</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>(Python and gym only required if gym environments
are used)</td>
</tr>
<tr>
<td>Materials:</td>
<td><a href="readme/README.html">README</a> <a href="news/news.html">NEWS</a> </td>
</tr>
<tr>
<td>CRAN&nbsp;checks:</td>
<td><a href="../../checks/check_results_reinforcelearn.html">reinforcelearn results</a></td>
</tr>
</table>
<h4>Downloads:</h4>
<table summary="Package reinforcelearn downloads">
<tr>
<td> Reference&nbsp;manual: </td>
<td> <a href="reinforcelearn.pdf"> reinforcelearn.pdf </a> </td>
</tr>
<tr>
<td>Vignettes:</td>
<td>
<a href="vignettes/agents.html">Agents</a><br/>
<a href="vignettes/environments.html">Environments</a><br/>
</td>
</tr>
<tr>
<td> Package&nbsp;source: </td>
<td> <a href="../../../src/contrib/reinforcelearn_0.2.1.tar.gz"> reinforcelearn_0.2.1.tar.gz </a> </td>
</tr>
<tr>
<td> Windows&nbsp;binaries: </td>
<td> r-devel: <a href="../../../bin/windows/contrib/4.1/reinforcelearn_0.2.1.zip">reinforcelearn_0.2.1.zip</a>, r-release: <a href="../../../bin/windows/contrib/4.0/reinforcelearn_0.2.1.zip">reinforcelearn_0.2.1.zip</a>, r-oldrel: <a href="../../../bin/windows/contrib/3.6/reinforcelearn_0.2.1.zip">reinforcelearn_0.2.1.zip</a> </td>
</tr>
<tr>
<td> macOS&nbsp;binaries: </td>
<td> r-release: <a href="../../../bin/macosx/contrib/4.0/reinforcelearn_0.2.1.tgz">reinforcelearn_0.2.1.tgz</a>, r-oldrel: <a href="../../../bin/macosx/el-capitan/contrib/3.6/reinforcelearn_0.2.1.tgz">reinforcelearn_0.2.1.tgz</a> </td>
</tr>
<tr>
<td> Old&nbsp;sources: </td>
<td> <a href="https://CRAN.R-project.org/src/contrib/Archive/reinforcelearn"> reinforcelearn archive </a> </td>
</tr>
</table>
<h4>Linking:</h4>
<p>Please use the canonical form
<a href="https://CRAN.R-project.org/package=reinforcelearn"><samp>https://CRAN.R-project.org/package=reinforcelearn</samp></a>
to link to this page.</p>
</body>
</html>
